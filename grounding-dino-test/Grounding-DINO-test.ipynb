{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some parts adapted from the official Grounding DINO implementation\n",
    "https://github.com/IDEA-Research/GroundingDINO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Mar 21 22:07:17 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 551.61                 Driver Version: 551.61         CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3070 ...  WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   51C    P8             12W /  100W |    2511MiB /   8192MiB |      1%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      3112    C+G   ...inaries\\Win64\\EpicGamesLauncher.exe      N/A      |\n",
      "|    0   N/A  N/A      9580    C+G   ...les\\Microsoft OneDrive\\OneDrive.exe      N/A      |\n",
      "|    0   N/A  N/A     13004    C+G   ...2txyewy\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     14248    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe      N/A      |\n",
      "|    0   N/A  N/A     15500    C+G   C:\\Program Files\\LGHUB\\lghub.exe            N/A      |\n",
      "|    0   N/A  N/A     15616    C+G   ...B\\system_tray\\lghub_system_tray.exe      N/A      |\n",
      "|    0   N/A  N/A     15916    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe      N/A      |\n",
      "|    0   N/A  N/A     16756    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A     18164      C   ...Programs\\Python\\Python38\\python.exe      N/A      |\n",
      "|    0   N/A  N/A     20044    C+G   ...x64__qmba6cd70vzyy\\ArmouryCrate.exe      N/A      |\n",
      "|    0   N/A  N/A     22180    C+G   ...r\\AppData\\Roaming\\Zoom\\bin\\Zoom.exe      N/A      |\n",
      "|    0   N/A  N/A     31664    C+G   ...al\\Discord\\app-1.0.9037\\Discord.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final text_encoder_type: bert-base-uncased\n"
     ]
    }
   ],
   "source": [
    "from groundingdino.util.inference import load_model, load_image, predict, annotate\n",
    "import cv2\n",
    "\n",
    "model = load_model(\"groundingdino/config/GroundingDINO_SwinT_OGC.py\", \"weights/groundingdino_swint_ogc.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple\n",
      "C:/Users/gener/Desktop/Refrigerator/Recipe_Ingredients/Kitchen Ingredients/validation\\apple\\Image_1.jpg\n",
      "C:/Users/gener/Desktop/Refrigerator/Recipe_Ingredients/Kitchen Ingredients/validation\\apple\\Image_10.jpg\n",
      "C:/Users/gener/Desktop/Refrigerator/Recipe_Ingredients/Kitchen Ingredients/validation\\apple\\Image_2.jpg\n",
      "C:/Users/gener/Desktop/Refrigerator/Recipe_Ingredients/Kitchen Ingredients/validation\\apple\\Image_3.jpg\n",
      "C:/Users/gener/Desktop/Refrigerator/Recipe_Ingredients/Kitchen Ingredients/validation\\apple\\Image_4.jpg\n",
      "C:/Users/gener/Desktop/Refrigerator/Recipe_Ingredients/Kitchen Ingredients/validation\\apple\\Image_5.jpg\n",
      "C:/Users/gener/Desktop/Refrigerator/Recipe_Ingredients/Kitchen Ingredients/validation\\apple\\Image_6.JPG\n",
      "C:/Users/gener/Desktop/Refrigerator/Recipe_Ingredients/Kitchen Ingredients/validation\\apple\\Image_7.jpg\n",
      "C:/Users/gener/Desktop/Refrigerator/Recipe_Ingredients/Kitchen Ingredients/validation\\apple\\Image_8.jpg\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [37], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m             image_source, image \u001b[38;5;241m=\u001b[39m load_image(IMAGE_PATH)\n\u001b[0;32m     20\u001b[0m             \u001b[38;5;28mprint\u001b[39m(IMAGE_PATH)\n\u001b[1;32m---> 21\u001b[0m             boxes, logits, phrases \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mcaption\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTEXT_PROMPT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mbox_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBOX_TRESHOLD\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mtext_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTEXT_TRESHOLD\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m#             print(phrases)\u001b[39;00m\n\u001b[0;32m     29\u001b[0m             annotated_frame \u001b[38;5;241m=\u001b[39m annotate(image_source\u001b[38;5;241m=\u001b[39mimage_source, boxes\u001b[38;5;241m=\u001b[39mboxes, logits\u001b[38;5;241m=\u001b[39mlogits, phrases\u001b[38;5;241m=\u001b[39mphrases)\n",
      "File \u001b[1;32m~\\Downloads\\GroundingDINO-main\\GroundingDINO-main\\groundingdino\\util\\inference.py:65\u001b[0m, in \u001b[0;36mpredict\u001b[1;34m(model, image, caption, box_threshold, text_threshold, device, remove_combined)\u001b[0m\n\u001b[0;32m     62\u001b[0m caption \u001b[38;5;241m=\u001b[39m preprocess_caption(caption\u001b[38;5;241m=\u001b[39mcaption)\n\u001b[0;32m     64\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 65\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m     68\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(image[\u001b[38;5;28;01mNone\u001b[39;00m], captions\u001b[38;5;241m=\u001b[39m[caption])\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "# IMAGE_PATH = \"combination.jpg\"\n",
    "TEXT_PROMPT = \"apple . banana . beetroot . bell pepper . cabbage . carrot . cauliflower . chili pepper . corn . cucumber . eggplant . garlic . ginger . grapes . jalepeno . kiwi . lemon . letuce . mango . onion . orange . paprika . pear . peas . pineapple . pomegranate . potato . radish . soy beans . spinach . sweetcorn . sweet potato . tomato . turnip . watermelon\"\n",
    "\n",
    "img_dir = \"C:/Users/gener/Desktop/Refrigerator/Recipe_Ingredients/Kitchen Ingredients/validation\"\n",
    "BOX_TRESHOLD = 0.4\n",
    "TEXT_TRESHOLD = 0.4\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for subdir, dirs, files in os.walk(img_dir):\n",
    "    for direct in dirs:\n",
    "        print(direct)\n",
    "        subfolder = os.path.join(img_dir, direct)\n",
    "        for image_name in os.listdir(subfolder):\n",
    "            IMAGE_PATH = os.path.join(subfolder, image_name)\n",
    "            image_source, image = load_image(IMAGE_PATH)\n",
    "            \n",
    "            print(IMAGE_PATH)\n",
    "            boxes, logits, phrases = predict(\n",
    "                                        model=model,\n",
    "                                        image=image,\n",
    "                                        caption=TEXT_PROMPT,\n",
    "                                        box_threshold=BOX_TRESHOLD,\n",
    "                                        text_threshold=TEXT_TRESHOLD\n",
    "                                    )\n",
    "#             print(phrases)\n",
    "            annotated_frame = annotate(image_source=image_source, boxes=boxes, logits=logits, phrases=phrases)\n",
    "            cv2.imwrite(\"results/\" + direct + image_name + \".jpg\", annotated_frame)\n",
    "#             break\n",
    "#         break\n",
    "#     break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda-gpt",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
